{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Hospital Names Worldwide via Wiki\n",
    "**Website: ** [List of Hospitals in the World via Wikipedia](https://en.wikipedia.org/wiki/Lists_of_hospitals)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Filtering out False Negatives\n",
    "list_of_noise = (\"Template\", \"List\",\"Category\", \"Not\", \"Guid\", \" \", \"\\n\", \"You\", \"Find\", \"Support\", \"Visit\", \"About\", \"How\",\n",
    "                 \"Permanent\", \"More\", \"Information\", \"Text\", \"Wiki\", \"Feature\", \"wmf\", \"History\", \"Since\", \"<\", \"ALERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Checks if the link has no page\n",
    "def check_content(soup):\n",
    "    \"\"\"\n",
    "    Checks whether the page that was returned has content    \n",
    "    \"\"\"\n",
    "    \n",
    "    for section in soup.find_all(\"div\"):\n",
    "        try:\n",
    "            if re.match(\"noarticletext\", section[\"class\"][0]):\n",
    "                return(False)\n",
    "        except:\n",
    "            continue\n",
    "    return (True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_list_format(name_list, new_soup, new_content_list):\n",
    "    \"\"\"\n",
    "    Retrieves all the list tags and extracts all list elements\n",
    "    \"\"\"\n",
    "    \n",
    "    # Checks if the wiki-page is not empty\n",
    "    if (check_content(new_soup)):\n",
    "        # Iterate through all unordered list\n",
    "        for ul in new_content_list:\n",
    "            # Iterate through all list elements \n",
    "            for li in ul.find_all(\"li\"):\n",
    "                try:\n",
    "                    if re.match(\"<a href|<a class\", str(li.contents[0])):\n",
    "                        try:\n",
    "                            if (re.match(\"List\", li.contents[0][\"title\"])):\n",
    "                                name_list.append(str(li.contents[0][\"title\"]))\n",
    "                            else:\n",
    "                                name_list.append(str(li.contents[0].contents[0]))\n",
    "                        except:\n",
    "                            continue\n",
    "                    else:\n",
    "                        try:\n",
    "                            if re.match(\"<a class\", str(li.contents[0])):\n",
    "                                    name_list.append(str(li.contents[0][\"title\"]))\n",
    "                            elif (not \"<\" in str(li.contents[0])):\n",
    "                                name_list.append(str(li.contents[0]))\n",
    "                        except:\n",
    "                               continue\n",
    "                except:\n",
    "                    continue\n",
    "    return(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_table_format(name_list, new_soup, content_list):\n",
    "    \"\"\"\n",
    "    Retrieves all the table tags and extracts the first element of each row\n",
    "    \"\"\"\n",
    "    \n",
    "    remove_navbox(new_soup)\n",
    "\n",
    "    for table in content_list:\n",
    "        tr_list = table.find_all(\"tr\")\n",
    "        for tr in tr_list[1:]:\n",
    "            try:\n",
    "                if re.match(\"<a href|<a class\", str(tr.td.contents[0])):\n",
    "                    name_list.append(str(tr.td.a.contents[0]))\n",
    "                else:\n",
    "                    name_list.append(str(tr.td.contents[0]))\n",
    "            except:\n",
    "                continue\n",
    "    return (name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_html(url):\n",
    "    \"\"\"\n",
    "    Retrieves html from webpage and returns content of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    response = get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    mw_output = soup.find(\"div\", class_=\"mw-parser-output\")\n",
    "    \n",
    "    return(soup, mw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_hospitals(hospitals):\n",
    "    \"\"\" Prints how many hospitals are in the list\"\"\"\n",
    "    hospitals = set(hospitals)\n",
    "    print(\"Number of Hospitals: {}\".format(len(hospitals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_hospitals(hospitals):\n",
    "    \"\"\" Prints all hospital names in the list\"\"\"\n",
    "    for hospital in hospitals:\n",
    "        print(hospital + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_navbox(soup):\n",
    "    \"\"\"\n",
    "    Removes the navigation box of each page\n",
    "    \"\"\"\n",
    "    for navbox in soup.find_all(\"div\", class_= \"navbox\"):\n",
    "        navbox.decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_from_US(name_list, new_soup, new_mw_output):\n",
    "    \"\"\"\n",
    "    Extracts content from the US page which are separated by state\n",
    "    \"\"\"\n",
    "    table_object = new_mw_output.find_all(\"table\")\n",
    "    \n",
    "    new_content_list = table_object[0].find_all(\"ul\")\n",
    "    states = retrieve_list_format(name_list, new_soup, new_content_list)\n",
    "\n",
    "    state_dir = [state.replace(\" \", \"_\") for state in states]\n",
    "    \n",
    "    for state in state_dir:\n",
    "        country_page = \"https://en.wikipedia.org/wiki/\" + state\n",
    "        if (state.startswith(\"List\")):\n",
    "            new_soup, new_mw_output = retrieve_html(country_page)\n",
    "            remove_navbox(new_soup)\n",
    "            \n",
    "            #print(state)\n",
    "            list_format_content = new_mw_output.find_all(\"ul\")\n",
    "            name_list = retrieve_list_format(name_list, new_soup, list_format_content)\n",
    "        \n",
    "            temp_name_list = []\n",
    "            table_format_content = new_mw_output.find_all(\"table\")\n",
    "            if (len(table_format_content) > 0):\n",
    "                table_content = retrieve_table_format(temp_name_list, new_soup, table_format_content)\n",
    "                name_list += [hospital for hospital in table_content]\n",
    "    \n",
    "    return(name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Page Webscrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def multi_webScrapper(url):  \n",
    "    \"\"\"\n",
    "    Scrapes through multiple pages, starting from the page \n",
    "    containing all the countries within a continent\n",
    "    \"\"\"\n",
    "    soup, mw_output = retrieve_html(url)\n",
    "    \n",
    "    # Removes all navbox within the page\n",
    "    remove_navbox(soup)\n",
    "        \n",
    "    content_list = mw_output.find_all(\"ul\")\n",
    "\n",
    "    # Stores all Hospital Names\n",
    "    name_list = []\n",
    "\n",
    "    for links in content_list:\n",
    "        for link in links.find_all(\"li\"):\n",
    "            try:\n",
    "                country_dir = link.contents[0].contents[0].replace(\" \", \"_\")\n",
    "                country_page = \"https://en.wikipedia.org/wiki/\" + country_dir\n",
    "                if (country_dir.startswith(\"List\")):\n",
    "                    new_soup, new_mw_output = retrieve_html(country_page)\n",
    "                    \n",
    "                    # Removes all navbox within the page\n",
    "                    remove_navbox(new_soup)\n",
    "                    \n",
    "                    if (country_dir == \"List_of_hospitals_in_the_United_States\"):\n",
    "                        name_list = extract_from_US(name_list, new_soup, new_mw_output)\n",
    "                    else:\n",
    "                        new_content_list = new_mw_output.find_all(\"ul\")\n",
    "                        name_list = retrieve_list_format(name_list, new_soup, new_content_list)\n",
    "                        \n",
    "                        temp_name_list = [] # Temporary stores content from tables\n",
    "                        table_format_content = new_mw_output.find_all(\"table\")\n",
    "                        if (len(table_format_content) > 0):\n",
    "                            table_content = retrieve_table_format(temp_name_list, new_soup, table_format_content)\n",
    "                            name_list += [hospital for hospital in table_content]\n",
    "                else:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # Filters out noise\n",
    "    new_name_list = []   \n",
    "    new_name_list = ([name for name in name_list if not name.startswith(list_of_noise) and len(name) > 3])\n",
    "    return(set(new_name_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Page Webscrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def single_webScrapper(url):\n",
    "    \"\"\"\n",
    "    Scrapes through a wiki page, to retrieve all hospital names\n",
    "    \"\"\"\n",
    "    \n",
    "    soup, mw_output = retrieve_html(url)\n",
    "    remove_navbox(soup)\n",
    "    content_list = mw_output.find_all(\"ul\")\n",
    "    table_content_list = mw_output.find_all(\"table\")\n",
    "    \n",
    "    # Stores all Hospital Names\n",
    "    name_list = []\n",
    "    temp_list = []\n",
    "    \n",
    "    # Retrieves content if in table format\n",
    "    if (len(table_content_list) > 0):\n",
    "        retrieve_table_format(name_list, soup, table_content_list)\n",
    "        \n",
    "    # Retrives content if in list format\n",
    "    retrieve_list_format(name_list, soup, content_list)\n",
    "\n",
    "    # Filters out noise\n",
    "    new_name_list2 = []   \n",
    "    new_name_list2 = ([name for name in name_list if not name.startswith(list_of_noise) and len(name) > 3])\n",
    "    return(new_name_list2)\n",
    "\n",
    "#single_webScrapper(\"https://en.wikipedia.org/wiki/List_of_hospitals_in_Argentina\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## North America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scraps for all North American hospitals\n",
    "na_hospitals = multi_webScrapper(\"https://en.wikipedia.org/wiki/Lists_of_hospitals_in_North_America\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Hospitals: 7491\n"
     ]
    }
   ],
   "source": [
    "# Number of hospitals in North America\n",
    "num_hospitals(na_hospitals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scraps for all European hospitals\n",
    "europe_hospitals = multi_webScrapper(\"https://en.wikipedia.org/wiki/Lists_of_hospitals_in_Europe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Hospitals: 3065\n"
     ]
    }
   ],
   "source": [
    "# Number of hospitals in Europe\n",
    "num_hospitals(europe_hospitals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asia_hospitals = multi_webScrapper(\"https://en.wikipedia.org/wiki/Lists_of_hospitals_in_Asia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Hospitals: 6714\n"
     ]
    }
   ],
   "source": [
    "# Number of hospitals in Asia\n",
    "num_hospitals(asia_hospitals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oceania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oceania_hospitals = multi_webScrapper(\"https://en.wikipedia.org/wiki/Lists_of_hospitals_in_Oceania\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Hospitals: 1250\n"
     ]
    }
   ],
   "source": [
    "# Number of hospitals in Oceania\n",
    "num_hospitals(oceania_hospitals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "africa_hospitals = multi_webScrapper(\"https://en.wikipedia.org/wiki/Lists_of_hospitals_in_Africa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Hospitals: 1658\n"
     ]
    }
   ],
   "source": [
    "# Number of hospitals in Africa\n",
    "num_hospitals(africa_hospitals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## South America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sa_hospitals = multi_webScrapper(\"https://en.wikipedia.org/wiki/Lists_of_hospitals_in_South_America\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Hospitals: 593\n"
     ]
    }
   ],
   "source": [
    "# Number of hospitals in Africa\n",
    "num_hospitals(sa_hospitals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def write_2_file(textfile, entity_list):\n",
    "    for entity in entity_list:\n",
    "        entity.replace(\"\\n\", \"\")\n",
    "        textfile.write(\"\\t\" + entity + \"\\n\")\n",
    "        \n",
    "    textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Write to File\n",
    "na_file = open(\"NA_Hospitals.txt\", \"w\", encoding = \"utf8\")\n",
    "write_2_file(na_file, na_hospitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to File\n",
    "europe_file = open(\"Europe_Hospitals.txt\", \"w\", encoding = \"utf8\")\n",
    "write_2_file(europe_file, europe_hospitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to File\n",
    "asia_file = open(\"Asia_Hospitals.txt\", \"w\", encoding = \"utf8\")\n",
    "write_2_file(asia_file, asia_hospitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to File\n",
    "oceania_file = open(\"Oceania_Hospitals.txt\", \"w\", encoding = \"utf8\")\n",
    "write_2_file(oceania_file, oceania_hospitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to File\n",
    "africa_file = open(\"Africa_Hospitals.txt\", \"w\", encoding = \"utf8\")\n",
    "write_2_file(africa_file, africa_hospitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to File\n",
    "sa_file = open(\"SA_Hospitals.txt\", \"w\", encoding = \"utf8\")\n",
    "write_2_file(sa_file, sa_hospitals)"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
